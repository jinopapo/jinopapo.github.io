<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[とてもつらい]]></title>
  <link href="http://jinopapo.github.io/atom.xml" rel="self"/>
  <link href="http://jinopapo.github.io/"/>
  <updated>2016-08-17T15:32:57+09:00</updated>
  <id>http://jinopapo.github.io/</id>
  <author>
    <name><![CDATA[Your Name]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[PRML3章]]></title>
    <link href="http://jinopapo.github.io/blog/2016/08/17/prml3/"/>
    <updated>2016-08-17T14:57:07+09:00</updated>
    <id>http://jinopapo.github.io/blog/2016/08/17/prml3</id>
    <content type="html"><![CDATA[<h1>線形回帰モデル<a id="orgheadline34"></a></h1>

<h2>線形基底関数モデル<a id="orgheadline29"></a></h2>

<p>任意の関数を基底関数として、重みパラメータに関する線形関数をつくり、入力xに対して目的変数tを推定する問題について考える。
最も簡単なモデルは、
\[y(x,w)=w_{0}+w_{1}x_{1}+&hellip;+w_{D}x_{D}\]
で表される。
これは、あまりに表現力がないので、拡張すると、
\[y(\mathbf{x},\mathbf{w})=w_{0}+\sum_{j=0}^{M-1}w_{j}\phi_{j}(\mathbf{x})\]
となる。\(\phi_{j}(\mathbf{x})\)を基底関数という。
また、\(w_{0}\)をバイアスパラメータという。
基底関数には、ガウス基底関数や、シグモイド基底関数、フーリエ基底関数などが用いられる。
最尤推定について考える。
推定したい関数yの出力にガウスノイズを乗せたものを目標変数にする。
\[t=y(x,w)+\epsilon\]
\(\epsilon\)はガウス分布に従うので、
\[p(t\mid x,w,\beta)=N(t\mid y(x,w),\beta^{-1})\]
で表せる。
誤差関数として、二乗損失関数を用いると最尤推定解は、条件付き期待値で与えられるので、
\[E[t\mid x]=\int tp(t\mid x)dt=y(x,w)\]
となる。
ここで、入力X={\(x_{1},&hellip;,x_{N}\)}と目的変数T={\(t_{1},&hellip;t_{N}\)}からなるデータ集合について考える。
二乗損失関数を用いて、対数尤度関数を考えると、
\[p(T\mid X,w,\beta)=\sum_{n=1}^{N}\ln N(t_{n}\mid w^{T}\phi(x_{n}),\beta^{-1})\
=\frac{N}{2}\ln\beta-\frac{N}{2}\ln(2\pi)-\beta E_{D}(W)\]
\[E_{D}(w)=\frac{1}{2}\sum_{n=1}^{N}\{t_{n}-w_{\mathrm{T}}\phi(x_{n})\}\]
となる。wの最尤推定解を求めると、
\[w_{ML}=(\Phi^{\mathrm{T}}\Phi)^{-1}\Phi^{\mathrm{T}}\mathbf{t}\]
となる。これは、最小二乗問題の正規方程式と言われる。\(\Phi\)は計画行列といわれ、その要素は、\(\Phi_{nj}=\phi_{j}(x_{n})\)であたえられる。
\[\Phi'\equiv(\Phi^{\mathrm{T}}\Phi)^{-1}\Phi^{\Phi^{\mathrm{T}}}\]
は、ムーア-アーペンローズの擬似逆行列と言われる。
\(\beta\)の最尤推定を求めると、
\[\frac{1}{\beta_{ML}}=\frac{1}{N}\sum_{n=1}^{N}\{t_{N}-w_{ML}^{\mathrm{T}\Phi(x_{n})}\}^{2}\]
となる。
逐次学習について考える。
確率的勾配降下法を適用して、逐次学習する。
誤差関数が、データ点の和からなっている場合、パラメータを
\[w^{\tau+1}=w^{\tau}-\eta\nabla E_{n}\]
を用いて更新していく。
今回の場合は、二乗誤差を更新していく。
また、過学習を防ぐために、正則化項を加えることを考えると誤差関数は、
\[E_{D}(w)+\lambda E_{W}(w)\]
で一般的に表せる。
最も単純な正則化項は
\[E_{W}(w)=\frac{1}{2}w^{\mathrm{T}}w\]
で与えられる。これは、逐次学習中に必要のない基底関数の重みが0に近づいていくので、荷重減衰といわれる。</p>

<h2>バイアスバリアンス分解<a id="orgheadline30"></a></h2>

<p>モデルの複雑差について考える。
線形基底関数モデルの期待二乗誤差は、
\[E[L]=\int \{y(x)-h(x)\}^{2}p(x)dx+\int \int \{h(x)-t\}^{2}p(x,t)dxdt\]
で表せる。h(x)は最適解を表す。
第二項は、ノイズを表すため、第一項を最小にするy(x)を求めるのが理想となる。
ここで、頻度主義での不確実性について考える。
頻度主義では、不確実性を複数のデータセットの平均で与える。
予測関数は、データセットごとで異なるので、y(x;D)で表す。
期待二乗誤差の第一項を各データ集合ごとの期待値\(E_{D}[y(x;D)]\)を用いて展開し、期待値を取ると、
\[E_{D}[\{y(x;D)-h(x)\}]=\{E_{D}[y(x;D)]-h(x)\}^{2}+E_{D}[\{y(x;D)-E_{D}[y(x;D)]\}^{2}]\]
となる。第一項はバイアスといわれ、理想値の離れ具合を示す。第二項は、バリアンスといわれ、データに対する敏感さを表す。
バリアンスとバイアスはトレードオフの関係にあり、適切に重みを選ぶ必要がある。
実際には、複数のデータセットが与えられることが少ないので、別のアプローチのほうがよい</p>

<h2>ベイズ線形回帰<a id="orgheadline31"></a></h2>

<p>ベイズ的な視点から、線形回帰モデルを扱う。
尤度関数\(P(t|w)\)がwのの二次関数の指数なので、事前分布は、
\[p(w)=N(w\mid m_{0},S_{0})\]
で表せる。
条件付きガウス分布の式より事後分布は、
\[p(w\mid t)=N(w\mid m_{N},S_{N})\]
\[m_{N}=S_{N}(S_{0}^{-1}m_{0}+\beta\Phi^{\mathrm{T}}t)\]
\[S_{N}^{-1}=S_{0}^{-1}+\beta\Phi^{\mathrm{T}}\Phi\]
となる。
簡単のため事前分布を、
\[p(w\mid \alpha)=N(w\mid 0,\alpha^{-1}I)\]
で表す。
ここでは、パラメータwではなく目的変数tがほしいので、予測分布について考える。
予測分布は、
\[p(t|\mathbf{t},\alpha,\beta)=\int p(t|w,\beta)p(w|\mathbf{t},\alpha,\beta)dw\]
で与えられる。
目的変数の条件付き分布、パラメータの事後分布は、ともに正規分布なので、
\[p(t|x,\mathbf{t},\alpha,\beta)=N(t|m_{N}^{T}\phi(x),\sigma^{2}_{N}(x))\]
\[\sigma_{N}^{2}=\frac{1}{\beta}+\phi(x)^{T}S_{N}\phi(x)\]
で表せる。
事前分布は、未知のパラメータによって、ガンマ分布や、ガウスーガンマ分布をつかいわける。
また、予測平均は、
\[y(x,m_{N})=\sum_{n=1}^{N}\beta\phi(x)^{T}S_{N}\phi(x_{n})t_{n}\]
で表わせ、目標変数tの線形結合として捉えれるので、
\[y(x,m_{N})=\sum_{n=1}^{N}k(x,x_{n})t_{n}\]
\[k(x,x^{\prime})=\beta\phi(x)^{\mathrm{T}}S_{N}\phi(x^{\prime})\]
と表せる。\(k(x,x^{\prime})\)を等価カーネルといい、目標変数の線形結合で、予測する回帰関数を線形平滑器という。
等価カーネルを用いると、各目標変数に重みを与えて、その線形結合で、新しいxに対する予測を出力することができる。</p>

<h2>ベイズモデル比較<a id="orgheadline32"></a></h2>

<p>ベイズの立場からのモデルの比較について考える。
頻度主義では、クロスバリデーションなどにでテスト用にデータをとって確認したが、ベイズでは一つのデータでできる。
L個のモデル\(M_{i}(i=1,&hellip;,L)\)について比較することを考える。
ベイズの定理を用いて、訓練集合Dが与えられた時の、モデルの事後分布
\[p(M_{i}|D)\propto p(M_{i})p(D|M_{i})\]
を評価する。この時の\(p(D|M_{i})\)は、モデルエビデンスといわれ、データから見たモデルの好みを表す。
二つのモデルのエビデンスの比を、ベイズ因子という。
モデルエビデンスは、
\[p(D|M_{i})=\int p(D|w,M_{i})p(w|M_{i})dw\]
で表わせ、尤度関数のパラメータwに関する周辺化として、捉えることもできる。
モデル選択により選ばれるモデルは、ベイズの観点においては、中間くらいの複雑さのモデルが選ばれる。</p>

<h2>エビデンス近似<a id="orgheadline33"></a></h2>

<p>事前分布のパラメータ\(\alpha\)、尤度関数のパラメータ\(\beta\)に関しても、データから推定することを考える。
ここでは、パラメータwに関して周辺化した周辺尤度を最大にするように、ハイパーパラメータ\(\alpha、\beta\)を決めるエビデンス近似について考える。
ハイパーパラメータに事前分布を追加すると、予測分布は、
\[p(t|\mathbf{t})=\int \int \int p(t|w,\beta)p(w|\mathbf{t},\alpha,\beta)p(\alpha,\beta|\mathbf{t})d\alpha d\beta dw\]
と表せる。入力xは省略。
事後分布\(p(\alpha,\beta|\mathbf{t})\)が\(\hat{\alpha}、\hat{\beta}\)で尖ってているとしたとき、予測分布は、
\[p(t|\mathbf{t},\hat{\alpha},\hat{\beta})=\int p(t|w,\hat{\beta})p(w|\mathbf{t},\hat{\alpha},\hat{\beta})dw\]
で表されるwの周辺化で近似できる。
ここで事後分布\(p(\alpha,\beta|\mathbf{t})\)について考える。
ベイズの定理より、
\[p(\alpha,\beta|\mathbf{t})\propto p(\mathbf{t}|\alpha,\beta)p(\alpha,\beta)\]
で事後分布が表される。
事前分布が比較的平坦なとき、尤度関数を最大にすることで、\(\hat{\alpha}\)と\(\hat{\beta}\)を得ることができる。
最大にするには、導関数を0とおき、方程式を解く方法とEMアルゴリズムを使う方法がある。
ここでは、方程式を解く方法について考える。
周辺尤度関数\(p(\mathbf{t}|\alpha,\beta)\)は、
\[p(\mathbf{t}|\alpha,\beta)=\int p(\mathbf{t}|w,\beta)p(w|\alpha)dw\]
で表すことができる。ここで、wの事前分布が\(N(w|0,\alpha^{-1})\)、尤度関数が、\(N(t|w^{\mathrm{T}}\phi(x),\beta^{-1})\)なので、
\[p(\mathbf{t}|\alpha,\beta)=(\frac{\beta}{2\pi})^{\frac{N}{2}}(\frac{\alpha}{2\pi})^{\frac{M}{2}}\int\exp\{-E(w)\}dw\]
\[E(w)=\frac{\beta}{2}||\mathbf{t}-\Phi w||^{2}+\frac{\alpha}{2}w^{T}w\]
と式変形ができる。
ここで、\(E(w)\)をwに関して平方完成すると、
\[E(w)=E(m_{n})+\frac{1}{2}(w-m_{N})^{\mathrm{T}}A(w-m_{N})\]
\[E(m_{N})=\frac{\beta}{2}||\mathbf{t}-\Phi m_{N}||^{2}+\frac{\alpha}{2}m_{N}^{T}m_{N}\]
\[A=\alpha I+\beta\Phi^{\mathrm{T}}\Phi\]
\[m_{N}=\beta A^{-1}\Phi^{T}\mathbf{t}\]
と表せる。このとき、\(m_{N}\)は事後分布の平均になる。
以上より対数尤度を取ると、
\[\ln p(\mathbf{t}|\alpha,\beta)=\frac{M}{2}\ln\alpha+\frac{N}{2}\ln\beta-E(m_{N})-\frac{1}{2}\ln|A|-\frac{N}{2}\ln(2\pi)\]
となる。
最初に、\(\alpha\)について考える。
まず、\(\ln|A|\)の微分について考える。
固有ベクトル方程式
\[(\beta\Phi^{\mathrm{T}}\Phi)u_{i}=\lambda_{i}u_{i}\]
より、\(A\)は固有値\(\alpha-\lambda_{i}\)をもつので、
\[\frac{d}{d\alpha}\ln|A|=\sum_{i}\frac{1}{\lambda_{i}+\alpha}\]
となる。
よって導関数を0とおくと、
\[0=\frac{M}{2\alpha}-\frac{1}{2}m_{N}^{\mathrm{T}}m_{N}-\frac{1}{2}\sum_{i}\frac{1}{\lambda_{i}+\alpha}\]
\[\alpha m_{N}^{\mathrm{T}}m_{N}=M-\alpha\sum_{i}\frac{1}{\lambda_{i}+\alpha}\]
\[\alpha m_{N}^{\mathrm{T}}m_{N}=\sum_{i}\frac{\lambda_{i}}{\lambda_{i}+\alpha}\]
となる。
この時の右辺を、\(\gamma\)とおくと、\(\alpha\)の最尤推定解は、
\[\alpha=\frac{\gamma}{m_{N}^{\mathrm{T}}m_{N}}\]
を満たすことがわかる。これは、最初に、\(\lambda\)と\(m_{N}\)を決め、\(\alpha\)を更新していき、収束するまで繰り返していくことで解ける。
次に\(\beta\)について考える。
\[\frac{d\lambda_{i}}{d\beta}=\frac{\lambda_{i}}{\beta}\]
より、
\[\frac{d}{d\beta}\ln|A|=\frac{\gamma}{\beta}\]
なので、導関数を0とおくと、
\[0=\frac{N}{2\beta}-\frac{1}{2}\sum_{n=1}^{N}\{t_{n}-m_{N}^{\mathrm{T}}\phi(x_{n})\}^{2}-\frac{\gamma}{2\beta}\]
\[\frac{1}{\beta}=\frac{1}{N-\gamma}\sum_{n=1}^{N}\{t_{n}-m_{N}^{\mathrm{T}}\phi(x_{n})\}^{2}\]
となる。これもさっきと同じように繰り返し計算して解ける。
また、この時、\(\gamma\)はデータによって影響を受けるパラメータ数、有効パラメータ数を示す。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[PRML2章]]></title>
    <link href="http://jinopapo.github.io/blog/2016/08/15/prml2/"/>
    <updated>2016-08-15T16:20:44+09:00</updated>
    <id>http://jinopapo.github.io/blog/2016/08/15/prml2</id>
    <content type="html"><![CDATA[<h1>確率分布<a id="orgheadline28"></a></h1>

<h2>二値変数<a id="orgheadline12"></a></h2>

<h3>ベルヌーイ分布<a id="orgheadline8"></a></h3>

<p>コイン裏表のように、結果が二値しかない場合の分布を考える。
x=1となる確率を\(\mu\)を使って
\[p(x=1|\mu)=\mu\]
と表すと確率分布は、
\[Bern(x|\mu)=\mu^{x}(1-\mu)^{1-x}\]
で表される。
これをベルヌーイ分布という。
平均と分散は、
\[E[x]=\mu\]
\[var[x]=\mu(1-\mu)\]</p>

<h3>二項分布<a id="orgheadline9"></a></h3>

<p>データがN個のときx=1となる分布を考える。
この時の分布を二項分布という。
二項分布は、全体をNx=1がになった回数をmとすると、
\[Bin(m|N,\mu)=\frac{N!}{(N-m)!m!}\mu^{m}(1-\mu)^{N-m}\]
となる。
平均と分散は
\[E[m]=N\mu\]
\[var[m]=N\mu(1-\mu)\]</p>

<h3>ベータ分布<a id="orgheadline10"></a></h3>

<p>二値の分布の事前分布にはベータ分布が用いられることが多い。
\(\gamma\)関数をもちいて
\[Beta(\mu|a,b)=\frac{\gamma(a+b)}{\gamma(a)\gamma(b)}\mu^{a-1}(1-\mu)^{b-1}\]
で表される。
平均と分散は、
\[E[\mu]=\frac{a}{a+b}\]
\[var[\mu]=\frac{ab}{(a+b)^{2}(a+b+1)}\]
となる。
a、bによって分布の方が代わるので、a、bをハイパーパラメータという。
事前分布に用いられる理由は、尤度関数が、\(\mu^{x}(1-\mu)^{1-x}\)に比例していて、事前分布にベータ分布を用いると事後分布も\(\mu^{x}(1-\mu)^{1-x}\)に比例するから。
これを性質を共役性という。</p>

<h3>比較<a id="orgheadline11"></a></h3>

<p>観測データDが得られたときの、頻度主義での分布モデルについて考える。
Dが独立して得られたとすると、尤度関数は
\[p(D|\mu)=\prod_{n=1}^{N}p(x_{n}|\mu)=\prod_{n=1}^{N}\mu^{x_{n}}(1-\mu)^{1-x_{n}}\]
で表わせる。これを対数を取り最尤推定すると、
\[\mu_{ML}=\frac{1}{N}\sum_{n=1}^{N}x_{n}\]
となる。
ベイズ主義からの分布モデルについて考える。
事後分布は、
\[p(\mu|m,l,a,b)=\frac{\gamma(m+a+l+b)}{\gamma(m+a)\gamma(l+b)}\mu^{m+a-1}(1-\mu)^{l+b-1}\]
となる。
また、この式から事後分布は事前分布からa、bをm、lだけ増やした形になっていて、データが増えた時に同じように分布が更新できることがわかる。
逐次学習中のある時間での分布は、
\[p(x=1|D)=\frac{m+a}{m+a+l+b}\]
となる。</p>

<h2>多値変数<a id="orgheadline15"></a></h2>

<h3>多項分布<a id="orgheadline13"></a></h3>

<p>多次元ベクトルで\(\sum_{k=1}^{K} x_{k}=1\)となるベクトルの分布を考える。
この時のxの分布は、
\[p(x|\mu)=\prod_{k=1}^{K}\mu_{k}^{x_{k}}\]
となり、ベルヌーイ分布を2種類以上の出力に一般化した物になる。
N個のデータ集合Dが得られたとすると尤度関数は、
\[p(D|\mu)=\prod_{n=1}^{N}\prod_{k=1}^{K}\mu_{k}^{x_{nk}}=\prod_{k=1}^{K}\mu_{k}^{\sum_{n}x_{nk}}=\prod_{k=1}^{K}\mu_{k}^{m_{k}}\]
となる。
よって、\(m_{k}=\sum_{n}x_{nk}\)に依存していることがわかる。
したがって、m<sub>k</sub>の同時確率分布について考えると
\[Mult(m_{1}&hellip;m_{k}|\mu,N=\frac{N!}{m_{1}!&hellip;m_{k}!})\prod_{k=1}^{K}mu_{k}^{m_{k}}\]
となる。
これは多項分布と呼ばれる。
これの最尤推定はラグランジュ乗数(\lambda)を用いて
\[\sum_{k=1}^{K}m_{k}ln\mu_{k}+\lambda(\sum_{k=1}^{K}\mu_{k}-1)\]
を最大化すると
\[\mu_{k}^{ML}=\frac{m_{k}}{N}\]</p>

<h3>ディリクレ分布<a id="orgheadline14"></a></h3>

<p>多項分布の共役分布を正規化すると、
\[Dir(\mu|\alpha)=\frac{\gamma(\alpha_{0})}{\gamma(\alpha_{1}..\gamma(\alpha_{k}))}\prod_{k=1}^{K}\mu_{k}^{\alpha_{k}-1}\]
となりディリクレ分布と呼ばれる。</p>

<h2>ガウス分布<a id="orgheadline23"></a></h2>

<p>よく使われる分布。
一変数の場合
\[N(x|\mu,\sigma^{2})\frac{1}{(2\pi\sigma^{2})^\frac{1}{2}}exp{-\frac{1}{2\sigma^{2}}(x-\mu)^{2}}\]
D次元ベクトルの場合
\[N(x|\mu,\sigma^{2})\frac{1}{(2\pi)^\frac{D}{2}}exp{-\frac{1}{2}(x-\mu)^{T}\sigma^{-1}(x-\mu)}\]
となる。
基本的には一つのピークを持つ分布なので、近似しにくいため、潜在変数や、非観測変数などを使っていろいろ近似する。</p>

<h3>条件付きガウス分布と周辺ガウス分布<a id="orgheadline16"></a></h3>

<p>ある二つの変数集合がガウス分布に従うなら、条件付き分布と、周辺分布も正規分布になる。
\(\Lambda=\sigma^{-1}\)とした同時確率正規分布\(N(x|\mu,\sigma)\)があるとし、
\[x=(x_{a},x_{b}) \]
\[\mu=(\mu_{a},\mu_{b})\]
\[\sigma=\left(
\begin{array}{cc}
\sigma_{aa} &amp; \sigma_{ab} \\
\sigma_{ba} &amp; \sigma_{bb}
\end{array}
\right)\]
\[\Lambda=\left(
\begin{array}{cc}
\Lambda_{aa} &amp; \Lambda_{ab} \\
\Lambda_{ba} &amp; \Lambda_{bb}
\end{array}
\right)\]
で分割する。
条件付きガウス分布は、
\[p(x_{a}|x_{b})=N(x_{a}|\mu_{a|b},\Lambda_{aa}^{-1})\]
\[\mu_{a|b}=\mu_{a}-\Lambda_{aa}^{-1}\Lambda_{ab}(x_{b}-\mu_{b})\]
この時の平均はx<sub>b</sub>に関する線形の式とみれるので、線形ガウス分布と言われる。
周辺ガウス分布は、
\[p(x_{a})=N(x_{a}|\mu_{a},\sigma_{aa})\]
で表される。
また周辺分布と条件付き分布が
\[p(x)=N(x|\mu,\Lambda^{-1})\]
\[p(y|x)=N(y|Ax+b,L^{-1})\]
で与えられたとき、ベイズの定理を用いるとyの周辺分布、条件付き分布は、
\[p(y)=N(y|A\mu+b,J^{-1}+A\Lambda^{-1}A^{T})\]
\[p(x|y)=N(x|\sigma{A^{T}L(y-b)+\Lambda\mu},\sigma)\]
\[\sigma=(\Lambda+A^{T}LA)^{-1}\]</p>

<h3>Robbins-Monroアルゴリズム<a id="orgheadline17"></a></h3>

<p>同時確率分布\(p(z,\theta)\)があるとき、zの条件付き確率を\(f(\theta)\)として定義する。
この関数を回帰関数という。
Robbins-Monroアルゴリズムでは、回帰関数の\(f(\theta^{*})=0\)となる点を探すことが目的となる。
\(\theta\)の逐次的な推定は、
\[\theta^{(N)}=\theta^{(N-1)}-a_{N-1}z(\theta^{(N-1)})\]
となる。
この時\(a_{n}\)は、
\[\lim_{Z \to \infty}a_{N}=0\]
\[\sum_{N=1}^{\infty}a_{N}=\infty\]
\[\sum_{N=1}^{\infty}a_{N}^{2}&lt;\infty\]
を満たす整数の系列でなければならない。</p>

<h3>ガンマ分布<a id="orgheadline18"></a></h3>

<p>\[Gam(\lambda|a,b)=\frac{1}{\Gamma(a)}b^{a}\lambda^{a-1}exp(-b\lambda)\]
で定義される分布。
平均と分散は、
\[E[\lambda]=\frac{a}{b}\]
\[var[\lambda]=\frac{a}{b^{2}}\]</p>

<h3>スチューデントのt分布<a id="orgheadline19"></a></h3>

<p>\begin{equation}
St(x\mid \mu,\lambda,\nu)=\frac{\Gamma(\frac{\nu}{2}+\frac{1}{2})}{\Gamma(\frac{\nu}{2})}(\frac{\lambda}{\pi\nu})^{\frac{1}{2}}[1+\frac{\lambda(x-\mu)^{2}}{\nu}]^{-\frac{\nu}{2}-\frac{1}{2}}
\end{equation}</p>

<p>で表される分布をt分布という。
\(\lambda\)は精度を表すが分散の逆数ではない。\(\nu\)は自由度。
一般的に正規分布よりもすそが広くロバスト性があるため、ノイズにつよい。
また最尤推定解は、EMアルゴリズムで求める。</p>

<h3>フォン・ミーゼス分布<a id="orgheadline20"></a></h3>

<p>ガウス分布で、周期的な変数を扱いたい時に使える分布。例えば、風向きの予測など。
二変数の正規分布は、
\[p(x_{1},x_{2})=\frac{1}{2\pi\sigma^{2}}\exp\{-\frac{(x_{1}-\mu_{1})^{2}+(x_{2}-\mu_{2}^{2})}{2\sigma^{2}}\}\]
で表せる。
極座標系で表現しなおし正規化すると、
\[p(\theta\mid\theta_{0},m)=\frac{1}{2\pi I_{0}(m)}\exp\{m\cos(\theta-\theta_{0})\}\]
\[I_{0}(m)=\frac{1}{2\pi}\int_{0}^{2\pi}\exp\{m\cos\theta d\theta\}\]
\[m=\frac{r_{0}}{\sigma^{2}}\]
r<sub>0</sub>、&theta;<sub>0</sub>は平均に変数の極座標系でのパラメータ、&theta;<sub>0</sub>は平均、mは集中パラメータで、精度パラメータと同じ、\(I_{0}(m)\)は正規化係数。
最尤推定解について考える。
対数尤度関数は、
\[\ln p(D\mid\theta_{0},m)=-N\ln(2\pi)-N\ln(I_{0}(m))+m\sum_{n=1}^{N}\cos(\theta_{n}-\theta_{0})\]
となり導関数を0として解くと、
\[\theta_{0}^{ML}=\tan^{-1}{\frac{\sum_{n}\sin\theta_{n}}{\sum_{n}\cos\theta_{n}}}\]
となる。
mに関しては、
\[A(m_{ML})=\frac{1}{N}\sum_{n=1}{N}\cos(\theta_{n}-\theta_{0}^{ML})\]
となる。</p>

<h3>頻度主義とベイズ主義の比較<a id="orgheadline21"></a></h3>

<p>最尤推定によって逐次学習を行う場合を考える。
正規分布から、データ点が得られたとすると対数尤度は
\[ln{p(X\mid &mu;,&sigma;)}=-\frac{ND}{2}ln{2\pi}-\frac{N}{2}ln|&sigma;|-\frac{1}{2}&sum;_{n=1}^{N}(x_{n}-&mu;)^{\mathrm{T}}&sigma;^{-1}(x_{n}-&mu;)\]
となる。
\(\mu\)について微分した導関数を0とおくと
\[&mu;_{ML}=\frac{1}{N}&sum;_{n=1}^{N}x_{n}\]
となる。
\(\sigma\)については複雑だが、計算すると
\[&sigma;=\frac{1}{N}&sum;_{n=1}^{N}(x_{n}-&mu;_{ML})(x_{n}-&mu;_{ML})^{\mathrm{T}}\]
になる。
この時の\(\sigma\)にはバイアスがかかっていて過小評価されているが、
\[&sigma;=\frac{1}{N-1}&sum;_{n=1}^{N}(x_{n}-&mu;_{ML})(x_{n}-&mu;_{ML})^{\mathrm{T}}\]
にすると真に近づく。
逐次学習についてかんがえるため、\(x_{n}が&mu;_{ML}\)に与える影響について考えると、
\[&mu;_{ML}^{(N)}=&mu;_{ML}^{(N-1)}+\frac{1}{N}(x_{N}-&mu;_{ML}^{(N-1)})\]
となり、逐次学習の定式化ができた。
しかし、いつもこれでできるわけではないので、Robbins-Monroアルゴリズムを適用する。
この時、根は最尤推定の解に相当し、zは観測データになる。
\(a_{N}=\frac{&sigma;^{2}}{N}\)とすると、ガウスの最尤推定の式と一致する。
ベイズ主義によって逐次学習を行う場合を考える。
未知の情報が何かによって事前分布の選び方が変わってくる。
平均が未知の場合の尤度は、\(\mu\)の関数となり
\[p(X\mid &mu;)=\frac{1}{(2\pi&sigma;^{2})^{\frac{N}{2}}}exp{-\frac{1}{2&sigma;^{2}}&sum;_{n=1}^{N}(x_{n}-&mu;)^{2}}\]
となり、事前分布には共役事前分布のガウス分布\(p(&mu;)=N(&mu;\mid &mu;_{0},&sigma;_{0}^{2})\)を選べばいいと解る。
この時、事後分布は、</p>

<p>\begin{equation}
p(\mu\mid X)=N(\mu\mid \mu_{N},\sigma_{N}^{2})
\end{equation}</p>

<p>\begin{equation}
\mu_{N}=\frac{\sigma^{2}}{N\sigma_{0}^{2}+\sigma^{2}}\mu_{0}+\frac{N\sigma_{0}^{2}}{N\sigma_{0}^{2}+\sigma^{2}}\mu_{ML}
\end{equation}</p>

<p>\begin{equation}
\frac{1}{\sigma_{N}^{2}}=\frac{1}{\sigma_{0}^{2}}+\frac{N}{\sigma^{2}}
\end{equation}</p>

<p>となる。
逐次学習については、尤度関数を事後分布に掛けあわせていくだけでよい・
分散が未知の場合の尤度関数は、精度\(\lambda\)を用いて</p>

<p>\begin{equation}
p(X|\lambda)\propto\lambda^{\frac{N}{2}}\exp\{-\frac{\lambda}{2}\sum^{N}_{n=1}(x_{n}-\mu)^{2}\}
\end{equation}</p>

<p>となり事前分布は、ガンマ分布\(Gam(&lambda;\mid a_{0},b_{0})\)を用いればいいとわかる。
事後分布は、</p>

<p>\begin{eqnarray}
p(\lambda\mid X)\propto Gam(\lambda\mid a_{N},b_{N}) \\
a_{N}=a_{0}+\frac{N}{2} \\
b_{N}=b_{0}+\frac{N}{2}\sigma^{2}_{ML}
\end{eqnarray}</p>

<p>となる。
平均と分散が未知の場合は、同時確率分布は</p>

<p>\begin{equation}
p(\mu,\lambda)\propto\exp\{-\frac{\beta\lambda}{2}(\mu-\frac{c}{\beta})^{2}\}\lambda^{\frac{\beta}{2}}\exp\{-(d-\frac{c^{2}}{2\beta})\lambda\}
\end{equation}</p>

<p>となる。c、d、\(\beta\)は定数である。
事前分布は、\(a=\frac{(1+\beta)}{2}、b=d-\frac{c^{2}}{2\beta}\)とすると</p>

<p>\begin{equation}
p(\mu,\lambda)=N(\mu\mid \mu_{0},(\beta\lambda)^{-1})Gam(\lambda\mid a.b)
\end{equation}</p>

<p>となる。
この分布は正規-ガンマ分布という。
D次元変数の場合についてかんがえる。
平均が未知の時は、事前分布はガウス分布になる。
分散が未知の場合は、事前分布は</p>

<p>\begin{eqnarray}
W(\Lambda\mid W,\nu)=B|\Lambda|^{\frac{(\nu-D-1)}{2}}\exp((-\frac{1}{2}\mathrm{Tr}(W^{-1}\Lambda))) \
B(W,\nu)=|W|^{\frac{\nu}{2}}(2^{\nu\frac{D}{2}}\pi^{D\frac{(D-1)}{4}}\prod_{i=1}^{D}\Gamma(\frac{\nu+1-i}{2}))^{-1}
\end{eqnarray}</p>

<p>となる。
これはウィシャート分布と言われ、\nuは、自由度パラメータ、Wは尺度行列、Bは正則化定数
分布と平均が未知の場合は、</p>

<p>\begin{equation}
p(\mu,\Lambda\mid \mu_{0},\beta,W,\nu)=N(\mu\mid \mu_{0},(\beta\Lambda)^{-1})W(\lambda\mid W,\nu)
\end{equation}</p>

<p>となり、ガウス-ウィシャート分布といわれる。</p>

<h3>混合ガウス分布<a id="orgheadline22"></a></h3>

<p>複雑なデータに関して一つのガウス分布だけでは、うまく近似できないことがある
複数個のガウス分布を重ねて混合ガウス分布にするとうまく近似できる
混合ガウス分布は
\[p(x)=\sum_{k=1}^{K}\pi_{k}N(x\mid\mu_{k},\sigma_{k})\]
\[\sum_{k=1}^{K}\pi_{k}\]
\[0\leq\pi_{k}\leq1\]
で表される。
\(N(x\mid\mu_{k},\sigma_{k})\)を混合要素、\(\pi_{k}\)を混合係数という。
また、混合係数を事前分布、混合要素を条件付き分布としてみると
\[p(x)=\sum_{k=1}^{K}p(k)p(x\mid k)\]
と表せて、これを負荷率という。
混合ガウス分布のパラメータの決定する方法について考える。
最尤推定で求めるとして、対数尤度関数は、
\[\ln p(X\mid \pi,\mu,\sigma)=\sum_{n=1}^{N}\ln{\sum_{k=1}^{K}\pi_{k}N(x_{n}\mid \mu_{k},\sigma_{k})}\]
となる。これを解くためには、EMアルゴリズムなどを使う。</p>

<h2>指数型分布族<a id="orgheadline24"></a></h2>

<p>\[p(x\mid \eta)=h(x)g(\eta)\exp\{\eta^{T}u(x)\}\]
で表されるのを指数型分布属という。
指数型分布族の尤度関数を求めるのに、必要なデータの値を十分統計量という。
指数型分布族では、一般に共役事前分布が存在する。
事前分布の一つとして、事後分布のあまり影響を与えないようにする無情報事前分布というものがある。
無情報事前分布の例として、平行移動不変性と、尺度不変性を持つ分布が挙げられる。
平行移動不変性を持つ分布は、
\[p(x\mid \mu)=f(x-\mu)\]
で表され、\(\mu\)を位置パラメータという。この時、分布は定数となる
尺度不変性を持つ分布は、
\[p(x\mid \sigma)=\frac{1}{\sigma}f(\frac{x}{\sigma})\]
で表され、\(\sigma\)は尺度パラメータという。この時、分布は、正規化できないので、変速事前分布と言われる。
変速事前分布をとった場合でも、事後分布が正規化できる場合は使われる</p>

<h2>ノンパラメトリック法<a id="orgheadline27"></a></h2>

<p>事前分布などを用いたパラメータを用いる方法ではなく、データ点から分布モデルをつくることについて考える。
D次元の分布p(x)からなるデータ点をもとに、p(x)を推定する。
小さな領域Rごとに密度が一定とみなせるほど、Rが小さく、平均が真に近くなるほどRにデータ点が含まれると仮定すると、
\[p(x)=\frac{K}{NV}\]
で近似できる。Kは領域に含まれるデータ点の数、Nはデータ点の総数、Vは領域の体積。</p>

<h3>カーネル密度推定<a id="orgheadline25"></a></h3>

<p>Vを固定し、領域内に含まれうKによってp(x)を推定する。
\[k(u)\geq0\]
\[\int k(u)du=1\]
を満たす任意の関数k(u)をカーネル関数として利用する。
Kは、
\[K=\sum_{n=1}^{N}k(\frac{x-x_{n}}{h})\]
により推定される。
このhがカーネル関数によって変換された空間の広さに値し、hを適切に選ぶとうまく近似できる。一般にカーネル関数には、ガウス関数が用いられる。</p>

<h3>最近傍法<a id="orgheadline26"></a></h3>

<p>Kを固定し、K個データ点が入るように、Vを決めp(x)を推定する。
いわゆるk近傍法。クラスタリングとかに使われる。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Prml1]]></title>
    <link href="http://jinopapo.github.io/blog/2016/08/14/prml1/"/>
    <updated>2016-08-14T16:56:46+09:00</updated>
    <id>http://jinopapo.github.io/blog/2016/08/14/prml1</id>
    <content type="html"><![CDATA[<h1>序論<a id="orgheadline7"></a></h1>

<h2>回帰の例<a id="orgheadline1"></a></h2>

<p>機械学習でできることの一つの回帰を例に雰囲気を説明する。
wに関する線形の式\(y(x)=\sum^{M}_{j=0}w_{j}x^{j}\)でsin関数を近似する。
この時のMはモデルの次数、wは学習によって調節されるパラメータを表す。
学習用データには、実際の問題と同じようにノイズを乗せたsin関数の値を用いる。
誤差関数には二法誤差を使う。
学習によってこの誤差関数を最小にする用にパラメータを調節していく。
この時モデルの次数はとても大切で、適切な次数でないと、表現力が足りなかったり、過学習してしまう。
ベイズの用に確率を使うと、モデルの複雑さには依存しなくなる。
この過学習を防ぐ方法としては、正則化がよく用いられる。
正則化とは、誤差関数にペナルティを課して、パラメータが大きくなり過ぎない用にすること。
これによりノイズに強くなったりする。
モデルの複雑さを決める方法としては、クロスバリデーションとかある。</p>

<h2>確率論<a id="orgheadline5"></a></h2>

<h3>ベイズ　<a id="orgheadline2"></a></h3>

<p>ランダムな繰り返し試行の頻度を確率とするのを、頻度主義また古典確率という。
ランダムな繰り返し試行の不確かさを確率とするのをベイズ主義という。
ベイズでは、自分たちパラメータw対するの知見を、事前確率p(w)という形で確率に組み込み、観測されたデータDはp(D|w)という形で表される。
頻度主義では、データを元に、パラメータを更新していくのに対し、ベイズでは、wの不確かさが更新されて行く。
これらを元にベイズの定理を適用すると、
\[p(w|D)=\frac{p(D|w)p(w)}{p(D)}\]
となり、wのそれっぽさが確率で出せる。
また、p(D|w)は、wに関する関数ともとれ、尤度関数という。
p(D)は
\[p(D)=\int p(D|w)p(w)dw\]
に変換でき、p(w|D)はwの式とみなせる。</p>

<h3>正規分布<a id="orgheadline3"></a></h3>

<p>事前分布としてよく用いられる正規分布について触れる。
正規分布は
\[N(x|\mu,\sigma)=\frac{1}{(2\pi\sigma^{2})^{\frac{1}{2}}}exp{-\frac{1}{2\sigma^{2}(x-\mu)^{2}}}\]
で表される。
\(\mu\)を平均\(\sigma^{2}\)を分散とする。
データ集合Xが与えられたときのパラメータの決め方について考える。
\(\mu\)と\(\sigma\)が与えられたときのデータ集合の発生確率は、
\[p(X|\mu,\sigma^{2})=\prod^{N}_{n=1}N(X_{n}|\mu,\sigma^{2})\]
となり、これが尤度関数になる。
対数尤度を取り、最小化する\(\mu_{ML}\)、\(\sigma^{2}_{ML}\)を求めると
\[\mu_{ML}=\frac{1}{N}\sum^{N}{n=1}x_{n}\]
\[\sigma^{2}_{ML}=\frac{1}{N}\sum^{N}{n=1}(x_{n}-\mu_{ML})^{2}\]
となり、それぞれサンプル平均、サンプル分散と言われる。
この時、サンプル平均は、すぐ真に近づくが、サンプル分散はなかなか近づかない。
これをバイアスという。</p>

<h3>回帰の例<a id="orgheadline4"></a></h3>

<p>確率から回帰の例をもう一度見る。
入力xに対して求めたい値tの発生確率が正規分布に従うとすると
\[p(t|x,w,\beta)=N(t|y(x,w),\beta^{-1})\]
となる。
訓練データ{X,T}を用いると
\[p(T|X,w,\beta)=\prod_{n=1}^{N}N(T_{n}|y(X_{n},w),\beta^{-1})\]
で尤度関数が定義でき、最尤推定によりモデルのパラメータを決めることができる。
これは、二乗誤差でパラメータを最適化すると同じ。
ベイズ的な視点から回帰の例をみる。
事前確率を
\[p(w|\alpha)=N(w|0,\alpha^{-1}I)\]
とするとwの事後確率は、
\[p(w|X,T,\alpha,\beta)\propto p(T|X,w,\beta)p(w|\alpha)\]
となる。
与えられたデータから、事後確率を最大にするwを求めるのをMAP推定という。
これは、正則化を用いて二乗誤差でwを最適化するのと同じ。
完全なベイズでは、予測分布を作るので
\[p(t|x,X,T)=\int p(t|x,w,\beta)p(w|X,T,\alpha,\beta)dw\]
となる　</p>

<h2>決定論<a id="orgheadline6"></a></h2>

<p>入力に対して出力を一意に決める問題。
クラスタリングの例をみる。
入力xをクラスC<sub>k</sub>に当てはめる。
アプローチとしては、<br/>
( a )p(x|C<sub>k</sub>)を求めてベイズの定理を使いp(C_{}k}|x)を求める。これは、同時確率分布を求められ、出力も入力も人工的に生成できるので生成モデルと言われる<br/>
( b )p(C<sub>k</sub>)を直接求める。識別モデルと言われる<br/>
( c )クラスC<sub>k</sub>を出力する関数を求める<br/>
の三種類がある。
( a )( b )のアプローチでは、クラスを決定するしきい値を求める問題がある。
最も簡単な誤識別を最小にする考え方では、単純にもっとも確率の高い物を選べばいい。
複雑な物を例として、誤認識したときの損失を最小にする考え方では、認識ごとに重みをつけそれを最小化するものを選ぶ。
別の方法としては、分からないものとして棄却する方法もある。あるしきい値をきめて、各クラスになる確率がしきい値以下なら分からないものとする。
( c )のアプローチでは、しきい値も全部決めてしまうので、何か変更があった時とか一から学習しなおしたりするので、汎用性にかける。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[window8.1でxubuntuをデュアルブート]]></title>
    <link href="http://jinopapo.github.io/blog/2015/12/03/window8-dot-1dexubuntuwodeyuarubuto/"/>
    <updated>2015-12-03T00:56:30+09:00</updated>
    <id>http://jinopapo.github.io/blog/2015/12/03/window8-dot-1dexubuntuwodeyuarubuto</id>
    <content type="html"><![CDATA[<p>windows8.1でxubuntuをデュアルブートする時にハマった。</p>

<p>自分の場合はグラボ側にメインのモニターを繋いでいて、当然xubuntuにはGPUのドライバーが入っていないので、ちょっとこっとエラーのメッセージが出てその後、何も出力されなくなるってことになった。</p>

<p>最初の数時間はエラーメッセージに気が付かなくて、いろいろいじりまわしてたけどマザボ側の出力に変えるだけで解決。</p>

<p>ようやくxubuntuが起動し、インストール。これはすんなりいった。</p>

<p>その後、なんやかんやGPUのドライバーを入れwindowの起動を確認し、その日は終了。</p>

<p>次の日立ち上げるとwindowしかた立ち上がらず,xubuntuはHDD上には存在しているが起動するデバイスが存在しないと言われ立ち上がらず。</p>

<p>調べてみると、windpow8は、windowを起動するたびにwindowのブートローダーを最優先にするらしく一回windowsを起動してしまうと、grubの優先度が下がり見えなくなってしまいubuntuが起動できなくなる仕様らしい。</p>

<p>これを解決するにはwindowsのブートローダーを書き換えてubuntuをwindowsのブートローダーから立ち上がるようにするか、windowのブートローダーをgrubで上書きするのがいいらしい。</p>
]]></content>
  </entry>
  
</feed>
